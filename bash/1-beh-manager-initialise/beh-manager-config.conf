#此文件是beh-manager安装脚本的配置文件
#请按要求填写下面内容

#timeline地址
timeline.server=132.90.116.136
#rest地址
rest.url=132.90.116.135
#web地址
web.url=132.90.116.135
#aiops地址和端口
aiops.url=132.90.116.135
aiops.port=18080
#execute地址和端口
execute.url=132.90.116.135
execute.port=8000

#neo数据库
spring.data.neo4j.uri=172.16.31.125
neo4j.port=7687
spring.data.neo4j.username=neo4j
spring.data.neo4j.password=123456

#指定一台spark on yarn的机器
spark.on.yarn.hostname=hadoop001


#集群安装基础路径
dir.base=/opt/beh


#rest端口
rest.port=8080
#timeline端口
timeline.port=8070
#web端口
web.port=8090
#registry端口
registry.port=8761

#agent端口
agent.port=8050
#config端口
config.port=8888






#请输入集群名字，给你的集群起个名字
clusterName=es_123
#输入用来收集hdfs监控的主机名
monitor.component.host=d8pnode1
#请输入registry注册中心和config中心的IP地址，它俩为一个
manager-registry-service=132.90.116.135
#是否打开了hdfs安全认证
hdfs.auth.status=off
#请输入安全认证的名字
hdfs.auth.user.name=Unicom
#es的主节点地址
elasticsearch.url=132.90.116.135

#spark,master端口
spark.master.webui.port=8083

warn.host=d8pnode1
#数据库地址
mysql.ip=132.90.116.135
#数据库端口
mysql.port=3306
#数据库名字
mysql.name=beh-manager
#数据库用户名
mysql.username=root
#数据库密码
mysql.password=Mysql1234.
#是否ssh远程执行命令
agentExecute.State=on
#hive的账号密码
hive.userName=hadoop
hive.passWord=bonchadoop

#集群安装集群的账号密码和组
hadoop.name=hadoop
hadoop.passwd=hadoop
hadoop.group=hadoop
#hbase的配置文件地址，需要单独把集群内hbase-site.xml放在timeline节点上的某个位置，下面是默认位置，beh7.5需要hbase-site.xml中的内容供timeline读取
#所以请保证timeline节点上这个位置有这个文件
hbase.conf.path=/opt/beh/core/hbase/conf/hbase-site.xml
